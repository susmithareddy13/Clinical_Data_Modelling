{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4123e83",
   "metadata": {},
   "source": [
    "### DS casestudy Documentation\n",
    "\n",
    "1.\tThe given dataset is in the form of a text file. As the data was tab-separated, It was loaded into a dataframe using pandas read_csv.\n",
    "\n",
    "2.\tFirstly; shape,head, statistics of the data was checked.\n",
    "\n",
    "3.\tSecondly, searched for the missing values and could not find any.\n",
    "\n",
    "4.\tAlthough they were no missing values, expected some redundancy between the columns and checked for them.\n",
    "\n",
    "5.\tRemoved the found redundant columns.\n",
    "\n",
    "6.\tBy using describe () on the dataframe found the summary of the data. \n",
    "\n",
    "7.\tFrom the statistics found columns with all 0’s and all 1’s and removed those columns.\n",
    "\n",
    "8.\tThen separated the response variable from the predictor variables.\n",
    "\n",
    "9.\tStatistics of response variable implies that the data is unbalanced. They are high number of zero’s.\n",
    "\n",
    " \n",
    "10.\tFrom Correlation plot, it was evident that they are many features correlated to one another both positively and negatively. It also seems that the variables are interdependent.\n",
    "\n",
    "11.\tFrom the above analysis, we see that the data we are dealing with is wide and not balanced.\n",
    "\n",
    "12.\tThen split the prepared data using train_test_split method by setting the parameter shuffle = True from sklearn library model_selection by choosing the different train & test sizes and calculated the training and validation errors to check whether the model is overfitting or underfitting.\n",
    "\n",
    "\n",
    "13.\tAfter looking at the above two problems, initially implemented RandomForestClassifier by using sklearn with RandomizedSearchCV. As the random forest would handle large data with higher dimensions greatly. Class imbalance was controlled by Smote(over_sampling)\n",
    "14.\tMean squared error, confusion matrix, accuracy, and classification report for different test sizes has been calculated. Obtained results were good.\n",
    "\n",
    "15.\tBut in real-world scenarios where we work with real-time health data, we would not be using any of the oversampling techniques. As the data is unbalanced and model should not overfit the data. Logistic regression with lasso regularization was other model which was implemented.\n",
    "\n",
    "16.\tAgain, mean squared error, confusion matrix, accuracy, and classification report for different test sizes has been calculated. \n",
    "\n",
    "17.\tValidated both the models by dividing the dataset into 60% train, 20% test and 20% validation and calculated the errors.\n",
    "\n",
    "18.\tAlso performed 5-fold cross-validation, so as to measure the performance of the models plotted roc curve for each iteration.\n",
    "\n",
    "19.\tFinally mean accuracy score, mean validation errors, mean training errors and mean AUC of both the models has been calculated.\n",
    "\n",
    "ROC for Random Forest Classifier \n",
    " \n",
    "ROC for Logistic Regression\n",
    " \n",
    "\n",
    "Conclusion:\n",
    "As the given data is unbalanced, accuracy is not a good metric. Based on the training error and the test error the model is neither overfitting nor underfitting. Model 1 performs better than Model 2 as the data considered is balanced.\n",
    "Both the models have low root mean squared error values and low false negatives values.\n",
    "\n",
    "\n",
    "Future Work:\n",
    "In model 1 instead of oversampling, under sampling can be used in the health industry when there is large amount of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cdfba",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "glmnet==2.1.1\n",
    "joblib==0.14.1\n",
    "numpy==1.18.1\n",
    "scikit-learn==0.22.1\n",
    "scipy==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81cc4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc, classification_report, mean_squared_error, roc_curve, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Loading data\n",
    "\n",
    "data_df = pd.read_csv(\n",
    "    'C:\\\\Users\\\\Ancha Harika\\\\Desktop\\\\tempus\\\\DScasestudy.txt', sep=\"\\t\")\n",
    "data_df.head()\n",
    "data_df.tail()\n",
    "data_df.describe()\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "\n",
    "# Checking for missing values\n",
    "data_df.isnull().sum().sum()\n",
    "# Removing duplicates\n",
    "reduced_data_df = data_df.T.drop_duplicates(keep='first').T\n",
    "reduced_data_df.drop(columns=['V4', 'V6'])\n",
    "# Separating response from features\n",
    "X_variables = reduced_data_df.drop(['response'], axis=1)\n",
    "response = reduced_data_df[['response']]\n",
    "# Dividing the data into training and testing data sets 60/40\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_variables, response, test_size=0.4, shuffle=True, random_state=999)\n",
    "# Dividing data into testing and training data sets 70/30\n",
    "x_train_30, x_test_30, y_train_30, y_test_30 = train_test_split(\n",
    "    X_variables, response, test_size=0.3, shuffle=True, random_state=999)\n",
    "# Dividing data into testing and training data sets 60---40\n",
    "x_train_20, x_test_20, y_train_20, y_test_20 = train_test_split(\n",
    "    X_variables, response, test_size=0.2, shuffle=True, random_state=999)\n",
    "# Using ggplot\n",
    "plt.style.use('ggplot')\n",
    "x = ['0', '1']\n",
    "unique_values_frequency = [407, 123]\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "# Plotting the frequency of 1's and 0's in response column\n",
    "plt.bar(x_pos, unique_values_frequency, color='green')\n",
    "plt.xlabel(\"1's and 0's\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Bar Chart 1's and 0's\")\n",
    "plt.xticks(x_pos, x)\n",
    "plt.show()\n",
    "\n",
    "# MODEL 1  (RandomForestClassifier)\n",
    "\n",
    "\n",
    "def model_train_error(X_train, y_train, model):\n",
    "    ''' Caluculates the training error of the given model\n",
    "        Args:\n",
    "        X_train(dataframe) : feature training data\n",
    "        y_train(dataframe) : response training data\n",
    "        model : model implemented \n",
    "        Returns:\n",
    "        mse : mean squared error\n",
    "    '''\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def model_validation_error(X_test, y_test, model):\n",
    "    ''' Caluculates the testing error of the given model\n",
    "        Args:\n",
    "        X_test(dataframe) : feature testing data\n",
    "        y_test(dataframe) : response testing data\n",
    "        model : model implemented \n",
    "        Returns:\n",
    "        mse : mean squared error\n",
    "    '''\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse\n",
    "\n",
    "\n",
    "def errors(trainig_x, training_y, testing_x, testing_y, your_model):\n",
    "    ''' Prints Testing and Training error's\n",
    "        Args:\n",
    "        trainig_x(dataframe) : feature training data\n",
    "        training_y(dataframe) : response training data\n",
    "        testing_x(dataframe) : feature testing data\n",
    "        testing_y(dataframe) : response testing data\n",
    "        your_model : model implemented \n",
    "    '''\n",
    "    print(\"train_error\", model_train_error(trainig_x, training_y, your_model))\n",
    "    print(\"test_error\", model_validation_error(\n",
    "        testing_x, testing_y, your_model))\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "class_weight = ['balanced']\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight': class_weight}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 5 fold cross validation,\n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf, param_distributions=random_grid, n_iter=100, cv=5, verbose=2,\n",
    "    random_state=99, n_jobs=-1)\n",
    "# Fit the RandomForestClassifier model 60/40\n",
    "sm = SMOTE(random_state=2)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_train, y_train['response'])\n",
    "rf_40 = rf_random.fit(x_train_res, y_train_res)\n",
    "# Predict model\n",
    "# Using the forest's predict method on the test data\n",
    "predictions_40 = rf_40.predict(x_test)\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test, predictions_40))\n",
    "print(classification_report(y_test, predictions_40))\n",
    "print(\"mean squared error\", mean_squared_error(y_test, predictions_40))\n",
    "print(\"accuracy\", accuracy_score(y_test, predictions_40))\n",
    "errors(x_train_res, y_train_res, x_test, y_test, rf_random)\n",
    "# Fit the RandomForestClassifier model 70/30\n",
    "x_train_res_30, y_train_res_30 = sm.fit_sample(\n",
    "    x_train_30, y_train_30['response'])\n",
    "rf_30 = rf_random.fit(x_train_res_30, y_train_res_30)\n",
    "# Predict model\n",
    "# Using the forest's predict method on the test data\n",
    "predictions_30 = rf_30.predict(x_test_30)\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test_30, predictions_30))\n",
    "print(classification_report(y_test_30, predictions_30))\n",
    "print(\"mean squared error\", mean_squared_error(y_test_30, predictions_30))\n",
    "print(\"accuracy\", accuracy_score(y_test_30, predictions_30))\n",
    "errors(x_train_res_30, y_train_res_30, x_test_30, y_test_30, rf_random)\n",
    "# Fit the RandomForestClassifier model\n",
    "x_train_res_20, y_train_res_20 = sm.fit_sample(\n",
    "    x_train_20, y_train_20['response'])\n",
    "rf_20 = rf_random.fit(x_train_res_20, y_train_res_20)\n",
    "# Predict model\n",
    "# Using the forest's predict method on the test data\n",
    "predictions_20 = rf_20.predict(x_test_20)\n",
    "print(\"Confusion Matrix\", confusion_matrix(y_test_20, predictions_20))\n",
    "print(classification_report(y_test_20, predictions_20))\n",
    "print(\"mean squared error\", mean_squared_error(y_test_20, predictions_20))\n",
    "print(\"accuracy\", accuracy_score(y_test_20, predictions_20))\n",
    "errors(x_train_res_20, y_train_res_20, x_test_20, y_test_20, rf_random)\n",
    "\n",
    "#           Model-1 validation\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_variables, response, shuffle=True, test_size=0.2, random_state=999)\n",
    "# train/validation split (gives us train and validation sets)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_val,\n",
    "                                                                y_train_val,\n",
    "                                                                shuffle=False,\n",
    "                                                                test_size=0.25,\n",
    "                                                                random_state=99)\n",
    "rfs = rf_random.fit(X_train, y_train)\n",
    "# print proportions\n",
    "print(\n",
    "    'train: {}% ; validation: {}% ; test {}%'.format(\n",
    "        round(len(y_train) / len(response),\n",
    "              2),\n",
    "        round(len(y_validation) / len(response),\n",
    "              2),\n",
    "        round(len(y_test) / len(response),\n",
    "              2)))\n",
    "# calculate errors\n",
    "new_train_error = mean_squared_error(y_train, rfs.predict(X_train))\n",
    "new_validation_error = mean_squared_error(\n",
    "    y_validation, rfs.predict(X_validation))\n",
    "new_test_error = mean_squared_error(y_test, rfs.predict(X_test))\n",
    "print(\"new train error\", new_train_error)\n",
    "print(\"new test error\", new_test_error)\n",
    "print(\"new validation error\", new_validation_error)\n",
    "\n",
    "#        Model-1's 5-fold cross validation\n",
    "\n",
    "sm = SMOTE(sampling_strategy='auto', k_neighbors=2, random_state=999)\n",
    "X_res, y_res = sm.fit_resample(X_variables, response['response'])\n",
    "print(\"number of unique values\", y_res.nunique())\n",
    "unique_values_count = y_res.value_counts()\n",
    "print(\"value counts of unique values\\n\", unique_values_count)\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=10000)\n",
    "train_errors = []\n",
    "validation_errors = []\n",
    "accuracy = []\n",
    "auc_array = []\n",
    "for train_index, val_index in kf.split(X_res, y_res):\n",
    "    # Split data\n",
    "    X_train, X_val = X_res.iloc[train_index], X_res.iloc[val_index]\n",
    "    y_train, y_val = y_res.iloc[train_index], y_res.iloc[val_index]\n",
    "    # Instantiate model\n",
    "    model_k = rf_random.fit(X_train, y_train)\n",
    "    # Predict model\n",
    "    predictions_kfold = model_k.predict(X_val)\n",
    "    print(\"Confusion Matrix\", confusion_matrix(y_val, predictions_kfold))\n",
    "    print(classification_report(y_val, predictions_kfold))\n",
    "    print(\"accuracy_score\", accuracy_score(y_val, predictions_kfold))\n",
    "    accuracy.append(accuracy_score(y_val, predictions_kfold))\n",
    "    predict_prob = model_k.predict_proba(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val, predict_prob[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    k = auc(fpr, tpr)\n",
    "    print(\"auc\", k)\n",
    "    auc_array.append(k)\n",
    "    # Calculate errors\n",
    "    train_error = model_train_error(X_train, y_train, model_k)\n",
    "    val_error = model_validation_error(X_val, y_val, model_k)\n",
    "    # Append to appropriate list\n",
    "    train_errors.append(train_error)\n",
    "    validation_errors.append(val_error)\n",
    "print(\"train_error mean\", sum(train_errors)/len(train_errors))\n",
    "print(\"validation_error mean\", sum(validation_errors)/len(validation_errors))\n",
    "print(\"accuracy_mean\", sum(accuracy)/len(accuracy))\n",
    "print(\"Auc_mean\", sum(auc_array)/len(auc_array))\n",
    "\n",
    "#    MODEL 2 (Logistic Regression with Lasso Regularization)\n",
    "\n",
    "# Dividing data into testing and training data sets 40/60\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X_variables, response, test_size=0.4, shuffle=True, random_state=999)\n",
    "log = LogisticRegression(penalty='l1', solver='saga',\n",
    "                         random_state=999, max_iter=10000, tol=1e-07, n_jobs=1)\n",
    "log_40 = log.fit(x_train, y_train)\n",
    "# Predict Model\n",
    "# Using Logistic predict model\n",
    "prediction_40 = log_40.predict(x_test)\n",
    "print(confusion_matrix(y_test, prediction_40))\n",
    "print(classification_report(y_test, prediction_40))\n",
    "print(\"mean squared error\", mean_squared_error(y_test, prediction_40))\n",
    "print(\"accuracy\", accuracy_score(y_test, prediction_40))\n",
    "errors(x_train, y_train, x_test, y_test, log_40)\n",
    "\n",
    "\n",
    "# Dividing data into testing and training data sets 30/70\n",
    "\n",
    "x_train_30, x_test_30, y_train_30, y_test_30 = train_test_split(\n",
    "    X_variables, response, test_size=0.3, shuffle=True, random_state=999)\n",
    "log_30 = log.fit(x_train_30, y_train_30)\n",
    "# Predict Model\n",
    "# Using Logistic predict model\n",
    "prediction_30 = log_30.predict(x_test_30)\n",
    "confusion_matrix(y_test_30, prediction_30)\n",
    "print(confusion_matrix(y_test_30, prediction_30))\n",
    "print(classification_report(y_test_30, prediction_30))\n",
    "print(\"mean squared error\", mean_squared_error(y_test_30, prediction_30))\n",
    "print(\"accuracy\", accuracy_score(y_test_30, prediction_30))\n",
    "errors(x_train_30, y_train_30, x_test_30, y_test_30, log_30)\n",
    "\n",
    "# Dividing data into testing and training data sets 40/60\n",
    "\n",
    "x_train_20, x_test_20, y_train_20, y_test_20 = train_test_split(\n",
    "    X_variables, response, test_size=0.2, shuffle=True, random_state=999)\n",
    "log_20 = log.fit(x_train_20, y_train_20)\n",
    "# Predict Model\n",
    "# Using Logistic predict model\n",
    "prediction_20 = log.predict(x_test_20)\n",
    "confusion_matrix(y_test_20, prediction_20)\n",
    "print(confusion_matrix(y_test_20, prediction_20))\n",
    "print(classification_report(y_test_20, prediction_20))\n",
    "print(\"mean squared error\", mean_squared_error(y_test_20, prediction_20))\n",
    "print(\"accuracy\", accuracy_score(y_test_20, prediction_20))\n",
    "errors(x_train_20, y_train_20, x_test_20, y_test_20, log_20)\n",
    "\n",
    "#      Model-2 validation\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X_variables, response, shuffle=True, test_size=0.2, random_state=999)\n",
    "# train/validation split (gives us train and validation sets)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_val,\n",
    "                                                                y_train_val,\n",
    "                                                                shuffle=False,\n",
    "                                                                test_size=0.25,\n",
    "                                                                random_state=99)\n",
    "\n",
    "log_fit = log.fit(X_train, y_train)\n",
    "print(\n",
    "    'train: {}% ; validation: {}% ; test {}%'.format(\n",
    "        round(len(y_train) / len(response),\n",
    "              2),\n",
    "        round(len(y_validation) / len(response),\n",
    "              2),\n",
    "        round(len(y_test) / len(response),\n",
    "              2)))\n",
    "# calculate errors\n",
    "# Predict Model\n",
    "new_train_error = mean_squared_error(y_train, log_fit.predict(X_train))\n",
    "new_validation_error = mean_squared_error(\n",
    "    y_validation, log_fit.predict(X_validation))\n",
    "new_test_error = mean_squared_error(y_test, log_fit.predict(X_test))\n",
    "print(\"new train error\", new_train_error)\n",
    "print(\"new test error\", new_test_error)\n",
    "print(\"new validation error\", new_validation_error)\n",
    "\n",
    "#       Model-2's 5-fold cross validation\n",
    "\n",
    "K = 5\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=10000)\n",
    "train_errors = []\n",
    "validation_errors = []\n",
    "accuracy = []\n",
    "auc_array = []\n",
    "for train_index, val_index in kf.split(X_variables, response):\n",
    "    # Split data\n",
    "    X_train, X_val = X_variables.iloc[train_index], X_variables.iloc[val_index]\n",
    "    y_train, y_val = response.iloc[train_index], response.iloc[val_index]\n",
    "    # Instantiate model\n",
    "    model_k = log.fit(X_train, y_train)\n",
    "    # Predict Model\n",
    "    predictions_kfold = model_k.predict(X_val)\n",
    "    print(\"Confusion Matrix\", confusion_matrix(y_val, predictions_kfold))\n",
    "    print(classification_report(y_val, predictions_kfold))\n",
    "    print(\"accuracy_score\", accuracy_score(y_val, predictions_kfold))\n",
    "    accuracy.append(accuracy_score(y_val, predictions_kfold))\n",
    "    predict_prob = model_k.predict_proba(X_val)\n",
    "    fpr, tpr, _ = roc_curve(y_val, predict_prob[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    k = auc(fpr, tpr)\n",
    "    print(\"auc\", k)\n",
    "    auc_array.append(k)\n",
    "    # Calculate errors\n",
    "    train_error = model_train_error(X_train, y_train, model_k)\n",
    "    val_error = model_validation_error(X_val, y_val, model_k)\n",
    "    # Append to appropriate list\n",
    "    train_errors.append(train_error)\n",
    "    validation_errors.append(val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f705a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f06c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e5f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc4951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188ce4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
